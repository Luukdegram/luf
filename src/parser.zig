const std = @import("std");
const ArrayList = std.ArrayList;
const Allocator = std.mem.Allocator;
const testing = std.testing;
const Lexer = @import("lexer.zig").Lexer;
const Token = @import("token.zig").Token;
const ast = @import("ast.zig");
const Node = ast.Node;
const Tree = ast.Tree;

/// Precendence represent the order of importance
/// The higher the value, the earlier it will be executed
/// This means a function call will be executed before a prefix,
/// and the product will be calculated before the sum.
const Precedence = enum {
    lowest,
    equals,
    less_greater,
    sum,
    product,
    prefix,
    call,

    /// Returns the integer value of the enum
    fn val(self: Precedence) usize {
        return @enumToInt(self);
    }
};

/// Determines the Precendence based on the given Token Type
fn findPrecedence(token_type: Token.TokenType) Precedence {
    return switch (token_type) {
        .equal, .not_equal => .equals,
        .less_than, .greater_than => .less_greater,
        .plus, .minus => .sum,
        .slash, .asterisk => .product,
        else => .lowest,
    };
}

/// Parser retrieves tokens from our Lexer and turns them into
/// nodes to create an AST.
pub const Parser = struct {
    current_token: Token,
    peek_token: Token,
    allocator: *Allocator,
    tokens: []const Token,
    index: u32,
    source: []const u8,

    pub const Error = error{ParserError} || std.mem.Allocator.Error || std.fmt.ParseIntError;

    /// Creates a new Parser, using the given lexer.
    /// Sets the current and peek token.
    pub fn init(allocator: *Allocator, lexer: *Lexer) !Parser {
        const tokens = try lexer.tokenize(allocator);
        var parser = Parser{
            .current_token = undefined,
            .peek_token = undefined,
            .allocator = allocator,
            .tokens = tokens,
            .index = 2,
            .source = lexer.source,
        };

        // set current and peek token
        parser.current_token = parser.tokens[0];
        parser.peek_token = parser.tokens[1];
        return parser;
    }

    /// Sets the current token to the peek token and retrieves a new
    /// token from the Lexer and sets its value to the peak token.
    fn next(self: *Parser) void {
        self.current_token = self.peek_token;
        self.peek_token = self.tokens[self.index];
        self.index += 1;
    }

    /// Parses the tokens that were generated by the lexer.
    /// Returns a `Tree` which owns the memory of the nodes.
    pub fn parse(self: *Parser) Error!Tree {
        var nodes = ArrayList(Node).init(self.allocator);
        defer nodes.deinit();

        while (!self.currentIsType(.eof)) {
            const node = try self.parseStatement();
            try nodes.append(node);

            if (!self.peekIsType(.eof)) {
                self.next();
            } else {
                break;
            }
        }

        return Tree{
            .nodes = try self.allocator.dupe(Node, nodes.items),
            .tokens = self.tokens,
            .allocator = self.allocator,
        };
    }

    /// Parses the statement into a node
    fn parseStatement(self: *Parser) Error!Node {
        return switch (self.current_token.type) {
            .constant, .mutable => self.parseDeclaration(),
            ._return => self.parseReturn(),
            else => self.parseExpressionStatement(),
        };
    }

    /// Parses a declaration
    fn parseDeclaration(self: *Parser) Error!Node {
        const tmp_token = self.current_token;

        if (!self.expectPeek(.identifier)) {
            return error.ParserError;
        }

        const val = self.source[self.current_token.start..self.current_token.end];
        const name = Node.Identifier{ .token = self.current_token, .value = val };
        if (!self.expectPeek(.assign)) {
            return error.ParserError;
        }

        self.next();

        const decl = try self.allocator.create(Node.Declaration);
        decl.* = .{
            .token = tmp_token,
            .name = name,
            .value = try self.parseExpression(.lowest),
        };

        return Node{ .declaration = decl };
    }

    /// Parses a return statement
    fn parseReturn(self: *Parser) Error!Node {
        const ret = try self.allocator.create(Node.Return);
        ret.* = .{ .token = self.current_token, .value = undefined };
        return Node{ ._return = ret };
    }

    /// Parses the current token as an Identifier
    fn parseIdentifier(self: *Parser) Error!Node {
        const identifier = try self.allocator.create(Node.Identifier);
        const val = self.source[self.current_token.start..self.current_token.end];
        identifier.* = .{ .token = self.current_token, .value = val };
        return Node{ .identifier = identifier };
    }

    /// Parses an expression statement, determines which expression to parse based on the token
    fn parseExpressionStatement(self: *Parser) Error!Node {
        const statement = try self.allocator.create(Node.Expression);
        statement.* = .{ .token = self.current_token, .expression = try self.parseExpression(.lowest) };
        return Node{ .expression = statement };
    }

    /// Determines the correct expression type based on the current token type
    fn parseExpression(self: *Parser, prec: Precedence) Error!Node {
        return switch (self.current_token.type) {
            .identifier => self.parseIdentifier(),
            .integer => self.parseIntegerLiteral(),
            else => blk: {
                var left = try self.parsePrefixExpression();

                if (prec.val() < findPrecedence(self.peek_token.type).val()) {
                    self.next();
                    left = try self.parseInfixExpression(left);
                }
                break :blk left;
            },
        };
    }

    /// Parses the current token into a prefix, errors if current token is not a prefix token
    fn parsePrefixExpression(self: *Parser) Error!Node {
        const temp = self.current_token;

        self.next();

        const expression = try self.allocator.create(Node.Prefix);
        expression.* = .{ .token = temp, .operator = temp.string(), .right = try self.parseExpression(.prefix) };

        return Node{ .prefix = expression };
    }

    /// Parses the current token into an infix expression
    fn parseInfixExpression(self: *Parser, left: Node) Error!Node {
        const expression = try self.allocator.create(Node.Infix);
        expression.* = .{
            .token = self.current_token,
            .operator = self.current_token.string(),
            .left = left,
            .right = undefined,
        };

        const prec = findPrecedence(self.current_token.type);
        self.next();
        expression.right = try self.parseExpression(prec);

        return Node{ .infix = expression };
    }

    /// Parses the current token into an integer literal node
    fn parseIntegerLiteral(self: *Parser) Error!Node {
        const literal = try self.allocator.create(Node.IntegerLiteral);
        const string_number = self.source[self.current_token.start..self.current_token.end];
        const value = try std.fmt.parseInt(usize, string_number, 10);

        literal.* = .{ .token = self.current_token, .value = value };
        return Node{ .int_lit = literal };
    }

    /// Determines if the next token is the expected token or not.
    /// Incase the next token is the wanted token, retun true and retrieve next token.
    fn expectPeek(self: *Parser, token_type: Token.TokenType) bool {
        if (self.peekIsType(token_type)) {
            self.next();
            return true;
        }
        return false;
    }

    /// Helper function to check if the peek token is of given type
    fn peekIsType(self: Parser, token_type: Token.TokenType) bool {
        return @enumToInt(self.peek_token.type) == @enumToInt(token_type);
    }

    /// Helper function to check if the current token is of given type
    fn currentIsType(self: Parser, token_type: Token.TokenType) bool {
        return @enumToInt(self.current_token.type) == @enumToInt(token_type);
    }
};

test "Parse Delcaration" {
    const input =
        \\const x = 5
        \\mut y = 54
        \\const z = 1571
    ;

    var allocator = testing.allocator;
    var lexer = Lexer.init(input);
    var parser = try Parser.init(allocator, &lexer);
    const tree = try parser.parse();
    defer tree.deinit();

    testing.expect(tree.nodes.len == 3);

    const identifiers = &[_][]const u8{
        "x", "y", "z",
    };

    var index: usize = 0;
    for (tree.nodes) |node| {
        if (node == .declaration) {
            const id = identifiers[index];
            index += 1;

            testing.expectEqualSlices(u8, id, node.declaration.name.value);
        }
    }
}

test "Parse Return statment" {
    const input =
        \\return 5
        \\return 10
        \\return 13957
    ;

    var allocator = testing.allocator;
    var lexer = Lexer.init(input);
    var parser = try Parser.init(allocator, &lexer);
    const tree = try parser.parse();
    defer tree.deinit();

    testing.expect(tree.nodes.len == 6);

    for (tree.nodes) |node| {
        if (node == ._return) {
            testing.expectEqualSlices(u8, node._return.token.string(), "return");
        }
    }
}

test "Parse identifier expression" {
    const input = "foobar";

    var allocator = testing.allocator;
    var lexer = Lexer.init(input);
    var parser = try Parser.init(allocator, &lexer);
    const tree = try parser.parse();
    defer tree.deinit();

    testing.expect(tree.nodes.len == 1);

    const identifier = tree.nodes[0].expression.expression.identifier;
    testing.expect(identifier.token.type == .identifier);
    testing.expectEqualSlices(u8, identifier.value, input);
}

test "Parse integer literal" {
    const input = "124";
    var allocator = testing.allocator;
    var lexer = Lexer.init(input);
    var parser = try Parser.init(allocator, &lexer);
    const tree = try parser.parse();
    defer tree.deinit();

    testing.expect(tree.nodes.len == 1);
    const literal = tree.nodes[0].expression.expression.int_lit;
    testing.expect(literal.token.type == .integer);
    testing.expect(literal.value == 124);
}

test "Parse prefix expressions" {
    const TestCase = struct {
        input: []const u8,
        operator: []const u8,
        expected: usize,
    };
    const test_cases = &[_]TestCase{
        .{ .input = "-5", .operator = "-", .expected = 5 },
        .{ .input = "+25", .operator = "+", .expected = 25 },
    };

    const allocator = testing.allocator;
    for (test_cases) |case| {
        var lexer = Lexer.init(case.input);
        var parser = try Parser.init(allocator, &lexer);
        const tree = try parser.parse();
        defer tree.deinit();

        testing.expect(tree.nodes.len == 1);

        const prefix = tree.nodes[0].expression.expression.prefix;
        const literal = prefix.right.int_lit;

        testing.expectEqualSlices(u8, case.operator, prefix.operator);
        testing.expect(case.expected == literal.value);
    }
}

test "Parse infix expressions" {
    
}
